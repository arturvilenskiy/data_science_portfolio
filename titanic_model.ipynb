{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Titanic Dataset: Predicting Survivability"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plan of Attack"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import Libaries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\r\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\r\n",
    "from sklearn.pipeline import Pipeline\r\n",
    "from sklearn.impute import SimpleImputer\r\n",
    "from sklearn.compose import ColumnTransformer\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\r\n",
    "from sklearn.naive_bayes import GaussianNB\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\r\n",
    "from xgboost import XGBClassifier\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings('ignore')\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "source": [
    "train = pd.read_csv('datasets/titanic_train.csv')\r\n",
    "X = train.drop('Survived', axis=1)\r\n",
    "y = train['Survived']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "source": [
    "features_remove = ['Name', 'Ticket', 'Cabin', 'Fare']\r\n",
    "X.drop(features_remove, axis=1, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "source": [
    "numeric_transformer = Pipeline(steps=[('imputer', SimpleImputer(missing_values=np.nan, strategy='median')), ('scaler', StandardScaler())])\r\n",
    "categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(missing_values=np.nan, strategy='most_frequent')), ('onehot', OneHotEncoder(handle_unknown='ignore'))])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "source": [
    "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\r\n",
    "categorical_features = X.select_dtypes(include=['object']).columns"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "source": [
    "preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numerical_features),('cat', categorical_transformer, categorical_features)])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "source": [
    "SEED=123\r\n",
    "lr = LogisticRegression(random_state=SEED,solver='liblinear')\r\n",
    "knn = KNN()\r\n",
    "dt = DecisionTreeClassifier(random_state=SEED)\r\n",
    "gaussian_nb= GaussianNB()\r\n",
    "randomforest=RandomForestClassifier(random_state=SEED)\r\n",
    "xgb = XGBClassifier(verbosity = 0)\r\n",
    "# Define a list called classifier that contains the tuples (classifier_name, classifier)\r\n",
    "classifiers = [('Logistic Regression', lr),('K Nearest Neighbours', knn),('Classification Tree', dt),('Gaussian Naive Bayes', gaussian_nb),('Random Forest', randomforest), ('XGBoost', xgb)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "source": [
    "for cls_name, clf in classifiers:\r\n",
    "    pipe = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', clf)])\r\n",
    "    pipe.fit(X_train, y_train)\r\n",
    "    accuracies = cross_val_score(pipe, X = X_train, y = y_train, cv = 10)\r\n",
    "    print(cls_name + \" Accuracy: {:.2f} %\".format(accuracies.mean()*100))\r\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Logistic Regression Accuracy: 80.39 %\n",
      "Standard Deviation: 3.21 %\n",
      "K Nearest Neighbours Accuracy: 79.79 %\n",
      "Standard Deviation: 5.98 %\n",
      "Classification Tree Accuracy: 72.31 %\n",
      "Standard Deviation: 5.58 %\n",
      "Gaussian Naive Bayes Accuracy: 78.74 %\n",
      "Standard Deviation: 3.57 %\n",
      "Random Forest Accuracy: 79.80 %\n",
      "Standard Deviation: 5.41 %\n",
      "XGBoost Accuracy: 79.21 %\n",
      "Standard Deviation: 5.52 %\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "source": [
    "params = {\r\n",
    "        'xgb__min_child_weight': [1, 5, 10],\r\n",
    "        'xgb__gamma': [0.5, 1, 1.5, 2, 5],\r\n",
    "        'xgb__subsample': [0.6, 0.8, 1.0],\r\n",
    "        'xgb__colsample_bytree': [0.6, 0.8, 1.0],\r\n",
    "        'xgb__max_depth': [3, 4, 5]\r\n",
    "        }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "source": [
    "pipe = Pipeline(steps=[('preprocessor', preprocessor), ('xgb', xgb)])\r\n",
    "pipe.fit(X_train, y_train)\r\n",
    "grid_search = GridSearchCV(pipe,\r\n",
    "                           params,\r\n",
    "                           n_jobs = -1)\r\n",
    "grid_search.fit(X_train, y_train)\r\n",
    "best_accuracy = grid_search.best_score_\r\n",
    "best_parameters = grid_search.best_params_\r\n",
    "print(\"Best Accuracy: {:.2f} %\".format(best_accuracy*100))\r\n",
    "print(\"Best Parameters:\", best_parameters)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best Accuracy: 83.84 %\n",
      "Best Parameters: {'xgb__colsample_bytree': 1.0, 'xgb__gamma': 1.5, 'xgb__max_depth': 3, 'xgb__min_child_weight': 5, 'xgb__subsample': 1.0}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "source": [
    "test = pd.read_csv('datasets/titanic_test.csv')\r\n",
    "xgb_upd = XGBClassifier(colsample_bytree=1, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1)\r\n",
    "pipe = Pipeline(steps=[('preprocessor', preprocessor), ('xgb', xgb_upd)])\r\n",
    "pipe.fit(X,y)\r\n",
    "test.drop(features_remove, axis=1, inplace=True)\r\n",
    "y_final_pred = pipe.predict(test)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "source": [
    "output = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': y_final_pred})\r\n",
    "output.to_csv('submission.csv', index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "ee6f022951eb6ed93b620ee25595bf1afceb274eb3637af1e721bcc987aa355b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}